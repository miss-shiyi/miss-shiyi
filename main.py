# -*- coding: utf-8 -*-
import argparse
import os
import re
from datetime import timezone
from github import Github, Auth
from marko.ext.gfm import gfm as marko
from feedgen.feed import FeedGenerator
from lxml.etree import CDATA

# --- æ–‡è‰ºé£é…ç½® ---
MD_HEAD = """# ğŸŒ™ miss-shiyi's Digital Garden
> **"ä¸å±äºä»»ä½•äººï¼Œä¹Ÿä¸æ‹¥æœ‰ä»»ä½•äººï¼Œå‡å°‘æœŸå¾…ï¼Œå¥½å¥½ç”Ÿæ´»ï¼Œæ­¤ç¨‹å±±é«˜è·¯è¿œï¼Œæˆ‘ç•™ç»™è‡ªå·±ã€‚"**
---
"""

BACKUP_DIR = "BACKUP"
ANCHOR_NUMBER = 5
TOP_ISSUES_LABELS = ["Top"]
TODO_ISSUES_LABELS = ["TODO"]
FRIENDS_LABELS = ["Friends"]
# å¿½ç•¥åˆ—è¡¨ï¼Œè¿™äº›æ ‡ç­¾ä¸ä¼šå•ç‹¬ä½œä¸ºåˆ†ç±»æ˜¾ç¤º
IGNORE_LABELS = FRIENDS_LABELS + TOP_ISSUES_LABELS + TODO_ISSUES_LABELS + ["bug", "help wanted", "invalid", "question"]

# åˆ†ç±»å›¾æ ‡æ˜ å°„
LABEL_ICONS = {"Python": "ğŸ", "Life": "ğŸŒ±", "Automation": "ğŸ¤–", "Code": "ğŸ’»", "Thoughts": "ğŸ’¡"}

def get_me(gh):
    me = os.getenv("GITHUB_NAME")
    return me if me else gh.get_user().login

def is_me(issue, me):
    return issue.user.login == me

def format_time(time):
    return time.strftime("%Y-%m-%d")

def _valid_xml_char_ordinal(c):
    codepoint = ord(c)
    return (0x20 <= codepoint <= 0xD7FF or codepoint in (0x9, 0xA, 0xD) or
            0xE000 <= codepoint <= 0xFFFD or 0x10000 <= codepoint <= 0x10FFFF)

# --- æ ¸å¿ƒåˆ†ç±»é€»è¾‘ (å‚è€ƒä½ åŸæ¥çš„å†™æ³•) ---
def add_md_label(repo, md_path, me):
    labels = repo.get_labels()
    sidebar_content = ["* [ğŸ  é¦–é¡µ](README.md)\n\n"]
    
    with open(md_path, "a+", encoding="utf-8") as md:
        md.write("## ğŸ“‚ æ–‡ç« åˆ†ç±»\n\n")
        
        for label in labels:
            if label.name in IGNORE_LABELS:
                continue

            # è·å–è¯¥æ ‡ç­¾ä¸‹çš„ Issue (å‚è€ƒä½ åŸæ¥çš„ get_issues_from_label)
            issues = repo.get_issues(labels=[label], state="open")
            
            if issues.totalCount:
                icon = LABEL_ICONS.get(label.name, "ğŸ”–")
                md.write(f"### {icon} {label.name}\n")
                sidebar_content.append(f"* **{icon} {label.name}**\n")
                
                # æ’åº
                sorted_issues = sorted(issues, key=lambda x: x.created_at, reverse=True)
                
                count = 0
                for issue in sorted_issues:
                    if not is_me(issue, me) or issue.pull_request:
                        continue
                        
                    if count == ANCHOR_NUMBER:
                        md.write("<details><summary>æ˜¾ç¤ºæ›´å¤š</summary>\n\n")
                    
                    # å†™å…¥ README
                    time_str = format_time(issue.created_at)
                    md.write(f"- `[{time_str}]` [{issue.title}]({issue.html_url})\n")
                    
                    # å†™å…¥ ä¾§è¾¹æ  (Docsify ä¸“ç”¨)
                    safe_title = issue.title.replace(" ", ".")
                    sidebar_content.append(f"  * [{issue.title}](BACKUP/{issue.number}_{safe_title}.md)\n")
                    count += 1
                
                if count > ANCHOR_NUMBER:
                    md.write("\n</details>\n")
                md.write("\n")

    # ç”Ÿæˆä¾§è¾¹æ æ–‡ä»¶
    with open("_sidebar.md", "w", encoding="utf-8") as sb:
        sb.writelines(sidebar_content)

def add_md_recent(repo, md_path, me, limit=5):
    with open(md_path, "a+", encoding="utf-8") as md:
        md.write("## ğŸ•’ æœ€è¿‘æ›´æ–°\n")
        issues = repo.get_issues(state="open", sort="updated")
        count = 0
        for issue in issues:
            if is_me(issue, me) and not issue.pull_request:
                time_str = format_time(issue.created_at)
                md.write(f"- `[{time_str}]` [{issue.title}]({issue.html_url})\n")
                count += 1
                if count >= limit: break
        md.write("\n---\n")

def generate_rss_feed(repo, filename, me):
    fg = FeedGenerator()
    fg.id(repo.html_url)
    fg.title(f"{me}'s Digital Garden")
    fg.link(href=repo.html_url, rel='alternate')
    for issue in repo.get_issues(state="open"):
        if not issue.body or not is_me(issue, me) or issue.pull_request:
            continue
        fe = fg.add_entry()
        fe.id(issue.html_url)
        fe.title(issue.title)
        fe.published(issue.created_at.replace(tzinfo=timezone.utc))
        body = "".join(c for c in issue.body if _valid_xml_char_ordinal(c))
        fe.content(CDATA(marko.convert(body)), type="html")
    fg.atom_file(filename)

def save_issue(issue, me, dir_name):
    # ä¿æŒä½ åŸæ¥çš„å‘½åä¹ æƒ¯ï¼šç¼–å·_æ ‡é¢˜.md
    safe_title = issue.title.replace(" ", ".")
    md_name = os.path.join(dir_name, f"{issue.number}_{safe_title}.md")
    with open(md_name, "w", encoding="utf-8") as f:
        f.write(f"# [{issue.title}]({issue.html_url})\n\n{issue.body}")

def main(token, repo_name, issue_number=None):
    auth = Auth.Token(token)
    gh = Github(auth=auth)
    me = get_me(gh)
    repo = gh.get_repo(repo_name)
    
    # é‡æ–°åˆå§‹åŒ– README
    with open("README.md", "w", encoding="utf-8") as md:
        md.write(MD_HEAD)
    
    # æŒ‰é¡ºåºæ‰§è¡Œæ¸²æŸ“
    add_md_recent(repo, "README.md", me)
    add_md_label(repo, "README.md", me)
    
    generate_rss_feed(repo, "feed.xml", me)
    
    if not os.path.exists(BACKUP_DIR):
        os.mkdir(BACKUP_DIR)
        
    for issue in repo.get_issues(state="open"):
        if is_me(issue, me) and not issue.pull_request:
            save_issue(issue, me, BACKUP_DIR)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("github_token")
    parser.add_argument("repo_name")
    parser.add_argument("--issue_number", default=None)
    args = parser.parse_args()
    main(args.github_token, args.repo_name, args.issue_number)
